{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "645791d8",
      "metadata": {},
      "source": [
        "# Human Evaluation (W4)\n",
        "\n",
        "Ce notebook sert à consolider les scores humains à partir de `docs/human_eval_template.csv`.\n",
        "\n",
        "1) Remplissez la feuille CSV avec les scores (1–5).\n",
        "2) Exécutez les cellules ci-dessous pour obtenir les moyennes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b2ca5bc",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import csv\n",
        "\n",
        "csv_path = Path(\"../docs/human_eval_template.csv\")\n",
        "print(\"CSV:\", csv_path.resolve())\n",
        "\n",
        "rows = []\n",
        "with csv_path.open(\"r\", encoding=\"utf-8\") as handle:\n",
        "    reader = csv.DictReader(handle)\n",
        "    for row in reader:\n",
        "        rows.append(row)\n",
        "\n",
        "print(\"Rows:\", len(rows))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49ba9d9d",
      "metadata": {},
      "outputs": [],
      "source": [
        "score_fields = [\n",
        "    \"coherence_1_5\",\n",
        "    \"creativity_1_5\",\n",
        "    \"faithfulness_1_5\",\n",
        "    \"overall_1_5\",\n",
        "]\n",
        "\n",
        "def to_float(value):\n",
        "    try:\n",
        "        return float(value)\n",
        "    except (TypeError, ValueError):\n",
        "        return None\n",
        "\n",
        "summary = {field: [] for field in score_fields}\n",
        "for row in rows:\n",
        "    for field in score_fields:\n",
        "        value = to_float(row.get(field, \"\"))\n",
        "        if value is not None:\n",
        "            summary[field].append(value)\n",
        "\n",
        "for field in score_fields:\n",
        "    values = summary[field]\n",
        "    if not values:\n",
        "        print(field, \"-> no scores yet\")\n",
        "    else:\n",
        "        avg = sum(values) / len(values)\n",
        "        print(field, \"avg:\", round(avg, 2), \"(n=\", len(values), \")\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d8ea693",
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "eval_summary = defaultdict(list)\n",
        "for row in rows:\n",
        "    evaluator = row.get(\"evaluator\", \"\").strip() or \"(unknown)\"\n",
        "    score = to_float(row.get(\"overall_1_5\", \"\"))\n",
        "    if score is not None:\n",
        "        eval_summary[evaluator].append(score)\n",
        "\n",
        "for evaluator, scores in eval_summary.items():\n",
        "    avg = sum(scores) / len(scores)\n",
        "    print(evaluator, \"overall avg:\", round(avg, 2), \"(n=\", len(scores), \")\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
